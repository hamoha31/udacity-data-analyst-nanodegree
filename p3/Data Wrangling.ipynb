{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Project with Python and MongoDB\n",
    "## 1.What is Data Wrangling?\n",
    "## 2.Project Explanation\n",
    "## 3.Data Exploration\n",
    "## 4.Conclusion\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.What is data wrangling?\n",
    "#### Definition: \n",
    "The process of manually converting or mapping data from one \"raw\" form into another format that allows for more convenient consumption of the data with the help of semi-automated tools.\n",
    "#### Why do we need it?\n",
    "After having the data, usually the data's shape is not consistant and clean. So, we need to reshape the data and clean unnecessary things. Espisally when we take data using web scrapping methods and when combining multiple sources of data together. \n",
    "#### Tools used:\n",
    "To clean (wrangle) data, you can do in one of many ways. The listed tools below are most used in these days.\n",
    "<ol>\n",
    "    <li>Manually by hand [Not good way with huge data].</li>\n",
    "    <li>Programming [Scripts to complete a spesific task, excellent with most cases].</li>\n",
    "    <li>Applications [Commerical or open source applications, most of them works with just a small list of data types].</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Project Explanation:\n",
    "###### The project aims to help the data analyst understanding the wrangling process, from getting data cleaning it and then store it on local database. \n",
    "This project is about the Open Street Map, which is a collaborative Geographical Information System (GIS). Open Street Map allows the community adding, updating and deleting data from maps. Open Street Map (OSM) lunched by Steve Coast 12 years ago and it has more than 3 milion users. \n",
    "\n",
    "###### How project works?\n",
    "To complate the project you need to download an OSM XML dataset for one of areas you are intrested in. Then audit the data in many ways.\n",
    "<ul>\n",
    "    <li>Languages</li>\n",
    "    <li>Data formats</li>\n",
    "    <li>Abbreviation</li>\n",
    "    <li>Etc...</li>\n",
    "</ul>\n",
    "\n",
    "Also, statistical overview of the dataset must be provided for:\n",
    "<ul>\n",
    "    <li>Size of the file</li>\n",
    "    <li>Total elements</li>\n",
    "    <li>Number of unique users</li>\n",
    "    <li>Number of nodes and ways</li>\n",
    "    <li>Number of chosen type of nodes, like cafes, shops etc.</li>\n",
    "    <li>Top 5 religons</li>\n",
    "    <li>Top 5 food types</li>\n",
    "    <li>Total Nando's resturants</li>\n",
    "    <li>Total number of Restaurants and Cafes</li>\n",
    "</ul>\n",
    "\n",
    "Finally, you need to provide suggestions for improving, analyzing the data and includes thoughtful discussion about the benefits as well as some anticipated problems in implementing the improvement.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Exploration\n",
    "I selected Cape Town, South Africa as my area to be cleaned. I will do the following steps:\n",
    "<ol>\n",
    "    <li>Download map's data</li>\n",
    "    <li>Prepare workspace</li>\n",
    "    <li>Select dataset file</li>\n",
    "    <li>Check file size</li>\n",
    "    <li>Calculate total tags</li>\n",
    "    <li>Calculate total users</li>\n",
    "    <li>Audit abbreviations</li>\n",
    "    <li>Convert data JSON</li>\n",
    "    <li>Storing data in MongoDB</li>\n",
    "    <li>Statistical overview</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Download Map's Data\n",
    "I Downloaded Cape Town from the https://mapzen.com/data/metro-extracts datasets. The dataset path is https://s3.amazonaws.com/metro-extracts.mapzen.com/cape-town_south-africa.osm.bz2\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Prepare Workspace\n",
    "I used **Python** and **MongoDB** to clean and query data. **Python** is one of the best languages for this task. It is very fast and lightweight. In the other side, **MongoDB** is one of the fastest NoSQL databases. I used it to store my dataset after cleaning it. It is very powerful tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.Select Dataset File\n",
    "My dataset is huge, so I have to create a sample to make the process faster. I created a Python script called **_sampler.py_** to make the sample. This allows us to check our code faster. The final result of the script it to make a **_sample.osm_** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The main file\n",
    "OSM_FILE = 'cape-town_south-africa.osm'\n",
    "# The sample file\n",
    "OSM_FILE = 'sample.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Check File Size\n",
    "The main dataset file's size is **283.0 MB** where the sample dataset file's size is **5.7 MB**. The dataset size has to be more than **50.00 MB**.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Calculate Total Tags\n",
    "The dataset is in XML like format, which means it made up from many open and close tags like this < tag >Content</ tag >. Knowing the tags count will help us understanding dataset structure and details. \n",
    "\n",
    "The below table list all tags in the dataset with its count.\n",
    "\n",
    "_To know more about tags you can check OpenStreetMap wiki._\n",
    "\n",
    "\n",
    "|    Tag   |  Count  |\n",
    "|:--------:|:-------:|\n",
    "|  bounds  |    1    |\n",
    "|  member  |  30724  |\n",
    "|    nd    | 1554908 |\n",
    "|   node   | 1350871 |\n",
    "|    osm   |    1    |\n",
    "| relation |   3033  |\n",
    "|    tag   |  604348 |\n",
    "|    way   |  212159 | \n",
    "\n",
    "\n",
    "Tags in the dataset can be one the following:\n",
    "\n",
    "    1- lower: valid tags in lowercase\n",
    "    \n",
    "    2- lower_colon: valid tags with a colon in their names\n",
    "    \n",
    "    3- problemchars: tags with problematic characters\n",
    "    \n",
    "    4- other: other tags that do not fall into the other three categories\n",
    "    \n",
    "\n",
    "\n",
    "|      Tag     |  Count |\n",
    "|:------------:|:------:|\n",
    "|     lower    | 555062 |\n",
    "|  lower_colon |  48113 |\n",
    "| problemchars |    7   |\n",
    "|     other    |  1166  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset set contains the above numbers of tags. Which means it is little bit big.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Calculate Total Users\n",
    "The number of users who helped in editing the map is very good indicator to know the comunity. A bigger number means more comunity, where a smaller number means usually using automated bots.\n",
    "\n",
    "Our dataset contains **1538 users** which is a good number.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.Audit Abbreviations\n",
    "##### 7.1 Audit Street Types:\n",
    "As we said before, our dataset contains many abbreviations, here we will list all appriviations and match them with current appriviations in the dataset. \n",
    "\n",
    "For example, **Rd.** will be changed with **Road**. This will give us a more consistent look and feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# A reguler expresion to check the last word in element name which is usally its type [street, road, etc...] \n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# What we want to see\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Commons\", \"Court\", \"Drive\", \"Lane\", \"Parkway\", \n",
    "                         \"Place\", \"Road\", \"Square\", \"Street\", \"Trail\", \"Circle\", \"Highway\"]\n",
    "\n",
    "# Mapping appriviations to expected.\n",
    "mapping = {'Ave'  : 'Avenue',\n",
    "           'Blvd' : 'Boulevard',\n",
    "           'Dr'   : 'Drive',\n",
    "           'Ln'   : 'Lane',\n",
    "           'Pkwy' : 'Parkway',\n",
    "           'Rd'   : 'Road',\n",
    "           'Rd.'   : 'Road',\n",
    "           'St'   : 'Street',\n",
    "           'st'   : 'Street',\n",
    "           'street' :\"Street\",\n",
    "           'stre' :\"Street\",\n",
    "           'stree' :\"Street\",\n",
    "           'Ct'   : \"Court\",\n",
    "           'Cir'  : \"Circle\",\n",
    "           'Cr'   : \"Court\",\n",
    "           'ave'  : 'Avenue',\n",
    "           'Hwg'  : 'Highway',\n",
    "           'Hwy'  : 'Highway',\n",
    "           'Sq'   : \"Square\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def audit_street(value):\n",
    "        m = street_type_re.search(value)\n",
    "        if m:\n",
    "            street_type = m.group()\n",
    "            if street_type not in expected:\n",
    "                new_type = mapping[street_type]\n",
    "                value = value.replace(street_type, new_type)\n",
    "        return value\n",
    "\n",
    "\n",
    "After auditing all items, a sample result is listed below. \n",
    "    \n",
    "    Old Name                      => New Name\n",
    "    Main Rd                       => Main Road\n",
    "    Foam Rd                       => Foam Road\n",
    "    Solan st                      => Solan Street\n",
    "    Caledon St                    => Caledon Street\n",
    "    De Villiers St                => De Villiers Street\n",
    "    New Church street             => New Church Street\n",
    "    Main Rd                       => Main Road\n",
    "    Barrack St                    => Barrack Street\n",
    "    Rhine Road & Eindhoven street => Rhine Road & Eindhoven Street\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 Audit Cities Names\n",
    "As we selected Cape Town, some small cities were selected with it. So, we are going to clean how cities writen. The way cities have to be writen is Capitel way. Which means cape Town, cape town, Cape town or cape-town are not accepted. It has to be Cape Town. \n",
    "\n",
    "I went over the data and made a set with cities names. Where I can make a list of all used names. Then I changed the wrong names with better ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Names in the dataset.\n",
    "expected_city_names = ['Abbotsdale', 'Athlone', 'Atlantis', 'Belgravia', 'Bellville',\n",
    "     'Bergvliet', 'Blouberg', 'Blue Downs', 'Bothasig', 'Brackenfell', 'Camps Bay', 'Cape Town',\n",
    "     'Capetown', 'Capricorn', 'Century City', 'Claremont', 'Constantia', 'De Tijger',\n",
    "     'Delft Cape Town', 'Diep River', 'Durbanville', 'Epping', 'Filippi',\n",
    "     'Foreshore, Cape Town', 'Gardens', 'Glencairn Heights', 'Goodwood', 'Gordons Bay',\n",
    "     'Grassy Park', 'Green Point', 'Hout Bay', 'Hout Bay Harbour', 'Hout Bay Heights Estate',\n",
    "     'Kalbaskraal', 'Kapstaden', 'Kenilworth', 'Khayelitsha', 'Killarney Gardens, Cape Town',\n",
    "     'Kommetjie', 'Kuilsriver', 'Kuilsrivier', 'Lansdowne', 'Loevenstein','Maitland',\n",
    "     'Makahza', 'Manenberg', 'Marina Da Gama', 'Melkbosstrand', 'Mfuleni',\n",
    "     'Milnerton', 'Milnerton,  Cape Town', 'Mitchells Plain', 'Mowbray', 'Mowbray, Cape Town',\n",
    "     'Muizenberg', 'Nerina Lane', 'Newlands', 'Noordhoek', 'Noordhoek, Cape Town', 'Nyanga',\n",
    "     'Observatory', 'Paarden Eiland' ,'Paarl' ,'Parklands' ,'Parow','Philadelphia',\n",
    "     'Pinelands','Plumstead','Pniel','Pringle Bay','Richwood','Rondebosch','Rondebosch East','Rondebosh East',\n",
    "     'Rosebank','Salt River','Scarborough','Sea Point','Sea Point, Cape Town',\"Simon's Town\",\n",
    "     'Somerset West','Sonnekuil','Steenberg','Stellenbosch','Stellenbosch Farms','Strand',\n",
    "     'Strandfotein','Suider Paarl','Sybrand Park','Table View','Techno Park','Technopark',\n",
    "     'Test city','Vredehoek','Vrygrond','Welgelegen 2','Welgemoed','Wellington','Woodstock',\n",
    "     'Woodstock, Cape Town','Wynberg','Zonnebloem']\n",
    "\n",
    "# Wrong names with better names.\n",
    "city_names_mapping = {\n",
    "         'cape Town' : \"Cape Town\",\n",
    "         'cape town' : \"Cape Town\",\n",
    "         'cape-town' : \"Cape Town\",\n",
    "         'Cape town' : \"Cape Town\",\n",
    "         'muizenberg' : \"Muizenberg\",\n",
    "         'rylands' : \"Rylands\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    def audit_city(value):\n",
    "        if value not in expected_city_names:\n",
    "            return city_names_mapping[value]\n",
    "        return value\n",
    "\n",
    "\n",
    "After auditing all items, a sample result is listed below.\n",
    "\n",
    "    Old Name   => New Name\n",
    "    cape town  => Cape Town\n",
    "    cape Town  => Cape Town\n",
    "    muizenberg => Muizenberg\n",
    "    cape Town  => Cape Town\n",
    "    cape Town  => Cape Town\n",
    "    rylands    => Rylands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.Convert Data to JSON\n",
    "Our dataset is in XML format. We are going to store data in MonogoDB, but before that we have to change dataset format from XML to JSON. \n",
    "\n",
    "To start doing that, we have to set the structure of the object, then start changing items based on it. \n",
    "\n",
    "A sample JSON object is below:\n",
    "\n",
    "    {\n",
    "        'pos':[-33.9322555, 18.8587291], \n",
    "        'type': 'node', \n",
    "        'id': '18401303', \n",
    "        'highway': 'traffic_signals', \n",
    "        'created': {\n",
    "            'changeset': '19306159', \n",
    "            'user': 'kaiD', \n",
    "            'version': '4', \n",
    "            'uid': '282726', \n",
    "            'timestamp': '2013-12-06T13:30:06Z'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "The dataset converted to JSON and saved localy.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.Store Data in MongoDB\n",
    "After cleaning data and store it in a clean structure, we are going to save it on local database using MongoDB. \n",
    "\n",
    "\n",
    "A long process ends with adding all items to the database.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.Statistical Overview\n",
    "The last step is about showing statistical overview about the database.\n",
    "<ul>\n",
    "    <li>Size of the file</li>\n",
    "    <li>Total elements</li>\n",
    "    <li>Number of unique users</li>\n",
    "    <li>Number of nodes and ways</li>\n",
    "    <li>Number of chosen type of nodes, like cafes, shops etc.</li>\n",
    "    <li>Top 5 religons</li>\n",
    "    <li>Top 5 food types</li>\n",
    "    <li>Total Nando's resturants</li>\n",
    "    <li>Total number of Restaurants and Cafes</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of the file\n",
    "What do you think, which file is bigger, the old or the new one?\n",
    "\n",
    "    The old file size is: 283.0 MB.\n",
    "    The new file size is: 324.6 MB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total elements\n",
    "Here is how we can count the number of elements in the database.\n",
    "\n",
    "    # total elements in DB\n",
    "    db.map.find().count()\n",
    "\n",
    "Total DB documants:  1563030\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique users\n",
    "Now we are going to calculate the number of users who participated in the map.\n",
    "\n",
    "    # total number of users\n",
    "    unique_users = len(db.map.distinct('created.user'))\n",
    "    print (\"Total users who participated in the map is: {} users.\".format(unique_users))\n",
    "    \n",
    "Total users who participated in the map is: 1529 users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of nodes and ways\n",
    "We are going to count the number of nodes and ways in the database.\n",
    "\n",
    "    # count items where type = way\n",
    "    total_ways = db.map.find({'type':'way'}).count()\n",
    "\n",
    "    # count items where type = node\n",
    "    total_nodes = db.map.find({'type':'node'}).count()\n",
    "\n",
    "    print (\"Total ways in the map is: {} ways.\".format(total_ways))\n",
    "    print (\"Total nodes in the map is: {} nodes.\".format(total_nodes))\n",
    "\n",
    "Total ways in the map is: 212127 ways.\n",
    "Total nodes in the map is: 1350860 nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of chosen type of nodes, like cafes, shops etc.\n",
    "We are going to see togather what are the most popular nodes in selected area.\n",
    "\n",
    "    amenities = db.map.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$amenity\",\n",
    "        \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "\n",
    "    pprint.pprint(list(amenities))\n",
    "\n",
    "\n",
    "    [\n",
    "         {u'_id': u'parking', u'count': 1719},\n",
    "         {u'_id': u'restaurant', u'count': 556},\n",
    "         {u'_id': u'school', u'count': 523},\n",
    "         {u'_id': u'toilets', u'count': 441},\n",
    "         {u'_id': u'drinking_water', u'count': 323},\n",
    "         {u'_id': u'place_of_worship', u'count': 307},\n",
    "         {u'_id': u'fuel', u'count': 302},\n",
    "         {u'_id': u'fast_food', u'count': 252},\n",
    "         {u'_id': u'waste_basket', u'count': 187},\n",
    "         {u'_id': u'atm', u'count': 174}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 religons \n",
    "We are going to investigate the **place_of_worship** to see top religons.\n",
    "\n",
    "    religions = db.map.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"place_of_worship\"}},\n",
    "                     {\"$group\":{\"_id\":\"$religion\", \"count\":{\"$sum\":1}}},{\"$sort\":{\"count\":-1}}, {\"$limit\":5}])\n",
    "    list(religions)\n",
    "    \n",
    "    [\n",
    "     {u'_id': u'christian', u'count': 239},\n",
    "     {u'_id': u'muslim', u'count': 35},\n",
    "     {u'_id': None, u'count': 23},\n",
    "     {u'_id': u'hindu', u'count': 5},\n",
    "     {u'_id': u'jewish', u'count': 5}\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 food types\n",
    "We are going to check best and top 5 food types [restaurant style].\n",
    "\n",
    "    places = db.map.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\"}},\n",
    "                               {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},\n",
    "                               {\"$sort\":{\"count\":-1}}, {\"$limit\":5}])\n",
    "    list(places)\n",
    "    \n",
    "    [\n",
    "        {u'_id': None, u'count': 311},\n",
    "        {u'_id': u'regional', u'count': 42},\n",
    "        {u'_id': u'italian', u'count': 24},\n",
    "        {u'_id': u'pizza', u'count': 21},\n",
    "        {u'_id': u'steak_house', u'count': 14}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Nando's resturants\n",
    "Nando's is one of the most famous restaurants in South Africa. Here we are going to count how many one exists in Cape Town. \n",
    "\n",
    "    nandos_count = db.map.find({\"$or\":[ {\"name\": \"Nando's\"}, {\"name\": \"Nandos\"}]}).count()\n",
    "\n",
    "    print \"Total Number of Nando's Resuturant:\", nandos_count\n",
    "\n",
    "Total Number of Nando's Resuturant: 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of Restaurants and Cafes\n",
    "For a city, to be a better place for visitors it has to contains as many resturants and cafes as possible. \n",
    "\n",
    "    eating_pleaces_count = db.map.find({\"$or\":[ {\"amenity\": \"cafe\"}, {\"amenity\": \"restaurant\"}]}).count()\n",
    "    print \"Number of restaurants and cafes:\", eating_pleaces_count\n",
    "\n",
    "Number of restaurants and cafes: 708\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Conclusion\n",
    "In conclusion, Open Street Map is an amazing project. It is going to help the community and improve many applications as it is an open source project. I liked the way how people participate in the project and help each other.\n",
    "\n",
    "I suggest the site managers help people developing automated bots to correct the data via Google Maps API. This will allow us to have a copy from Google Map data, also Google Maps will get benefits from the community. Using Google Map with OpenStreetMap via Google Places API for example will help OpenStreetMap improve places details.\n",
    "\n",
    "**Python Google Places** is a library to work with the API. You can find it here:\n",
    "\n",
    "https://github.com/slimkrazy/python-google-places\n",
    "\n",
    "This will allows us to search for location and fill empty details from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    # this is a smaple and imagination how we can change places details using API.\n",
    "    '''\n",
    "    for place in places:\n",
    "        if place.phone == None:\n",
    "            place.phone = API.find(place.geolocation).phone\n",
    "        if place.logo == None:\n",
    "            place.logo = API.find(place.geolocation).logo\n",
    "        ...\n",
    "            ...\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This soultion is very well, but we can not be 100% sure that data is correct. Maybe the old data is better than the new, so we are going to fill only empty attributes. \n",
    "\n",
    "\n",
    "Another improvment can be done by making competitions to improve data either manually or automated. This may be a wrong solution or idea becouse many people may add spam content to win.\n",
    "\n",
    "\n",
    "For the datasets structures I think adding a logo attribute to places is a good idea. As well as adding images for the place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Refs:*\n",
    "<ul>\n",
    "    <li>Wikipedia</li>\n",
    "    <li>Udacity</li>\n",
    "    <li>Stack Overflow</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
